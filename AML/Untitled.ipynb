{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "packed-turning",
   "metadata": {},
   "source": [
    "# Classyfing semester grades regarding alcohol consumption and family situation between youg people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-tissue",
   "metadata": {},
   "source": [
    "# uzasadnienie problemu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-glucose",
   "metadata": {},
   "source": [
    "#### necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "stupid-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from msrest.exceptions import HttpOperationError\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "from azureml.data.dataset_type_definitions import PromoteHeadersBehavior\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-wisdom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-sunrise",
   "metadata": {},
   "source": [
    "# Clean dataset locally\n",
    "\n",
    "At first we need to make some changes to input data to make dataset computable. It is not possible to easily apply changes and load them straight online. More convenient way is to apply operations locally and then upload data to cloud.\n",
    "\n",
    "So lets load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "italian-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_dataset = pd.read_csv('original_data/mat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-township",
   "metadata": {},
   "source": [
    "First we list all variables and decide which are relevant and which are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "superb-father",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
       "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
       "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
       "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all available collumns from dataset\n",
    "school_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-poetry",
   "metadata": {},
   "source": [
    "Let's mark the data that we don't want to analyze during classification\n",
    "* drop mothers and fathers job, beacause it is not properly identifiable and cannot be easily distinguished and classified\n",
    "* reason - why they picked this school -  irrelevant too\n",
    "* nursery - attended nursery school - i dont want to take that into consideration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "advanced-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# school_dataset.drop(['Mjob', 'Fjob', 'reason', 'nursery'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-lithuania",
   "metadata": {},
   "source": [
    "Let's convert other values to numeric representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "skilled-favor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# school - is binary because only two schools participated in study\n",
    "# GP - 1, MS - 0\n",
    "school_dataset['school'].replace({\"GP\": 1, \"MS\": 0}, inplace=True)\n",
    "school_dataset['school'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "distinguished-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sex, Female - 1, M - 0\n",
    "school_dataset['sex'].replace({\"F\": 1, \"M\": 0}, inplace=True)\n",
    "school_dataset['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "outer-break",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adress - U = urban places = 1, R = rural = 0\n",
    "school_dataset['address'].replace({\"U\": 1, \"R\": 0}, inplace=True)\n",
    "school_dataset['address'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "surrounded-malpractice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# famsize - family size indicatin LE3 - 0 (less or equal to 3), GT3 - 1 (greater than 3)\n",
    "school_dataset['famsize'].replace({\"GT3\": 1, \"LE3\": 0}, inplace=True)\n",
    "school_dataset['famsize'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "smooth-silicon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pstatus T - 1(Parents living together), A - 0 (Parents living apart)\n",
    "school_dataset['Pstatus'].replace({\"T\": 1, \"A\": 0}, inplace=True)\n",
    "school_dataset['Pstatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "convertible-skirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guardian: indicating influence of father(1)/mother(2)/other(0)\n",
    "school_dataset['guardian'].replace({\"father\": 1, \"mother\": 2, \"other\": 0}, inplace=True)\n",
    "school_dataset['guardian'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-southeast",
   "metadata": {},
   "source": [
    "### Convert yes/no information to 1/0 adequatly\n",
    "\n",
    "* schoolsup - extra educational support yes - 1, no - 0\n",
    "* famsup - family educational support yes - 1, no - 0\n",
    "* paid - extra paid classes in matter of subject yes - 1, no - 0\n",
    "* activities - extra paid acivities yes - 1, no - 0\n",
    "* higher - want to take higher education yes - 1, no - 0\n",
    "* internet - has internet access at home\n",
    "* romantic - with a romantic relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "sharp-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "yes_no_to_numeric = [\n",
    "    'schoolsup', 'famsup', 'paid', 'activities',\n",
    "    'higher', 'internet', 'romantic', 'nursery'\n",
    "]\n",
    "\n",
    "for col in yes_no_to_numeric:\n",
    "    school_dataset[col].replace({\"yes\": 1, \"no\": 0}, inplace=True)\n",
    "    print(school_dataset[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-grocery",
   "metadata": {},
   "source": [
    "## other dataset columns description\n",
    "\n",
    "* Medu -  Mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary\n",
    "* Fedu - Father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary\n",
    "* traveltime - Home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour)\n",
    "* studytime - Weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours)\n",
    "* failures - Number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4)\n",
    "* famrel - Quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "* freetime - Free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "* goout - Going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "* Dalc - Workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* Walc - Weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* health - Current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "* absences - Number of school absences (numeric: from 0 to 93)\n",
    "* G1 - First period grade (numeric: from 0 to 20)\n",
    "* G2 - Second period grade (numeric: from 0 to 20)\n",
    "\n",
    "## OUTPUT VARIABLE\n",
    "\n",
    "* G3 - Final grade (numeric: from 0 to 20, output target)\n",
    " ---\n",
    " \n",
    "#### or we can predict alcohol consumption basing on first two period grades Dalc, Walc ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "integrated-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data locally on disk\n",
    "school_dataset.to_csv('dataset/mat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-exemption",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "In this section we can specify which actions before or after script are going to be presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "adapted-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this variable indicates if we want to upload new dataset\n",
    "send_dataset_to_cloud = True\n",
    "#specify folder in which we have data for presentation\n",
    "local_dataset_source ='dataset'\n",
    "# indicate where do we upload our dataset in cloud and where do we get data from our cloud data blob\n",
    "upstream_dataset_path = 'datasets/tabular/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "valid-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#login to Microsoft account and connect with configured Azure workspace\n",
    "workspace = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-generic",
   "metadata": {},
   "source": [
    "Function `from_config` loads `config.json` file from directory where the notebook is run from.\n",
    "\n",
    "File looks like the following example\n",
    "\n",
    "```\n",
    "{\n",
    "    \"subscription_id\": \"<your azure subscription id>\",\n",
    "    \"resource_group\": \"<resource group name where your AML resource is placed>\",\n",
    "    \"workspace_name\": \"<AML workspace name>\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-installation",
   "metadata": {},
   "source": [
    "# Dataset from/to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "junior-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get default AML workspace datastore to get datasets or upload new ones\n",
    "datastore = workspace.get_default_datastore()\n",
    "\n",
    "# blob_datastore_name=os.getenv(\"BLOB_DATASTORE_NAME\") \n",
    "# account_name=os.getenv(\"BLOB_ACCOUNTNAME\") # Storage account name\n",
    "# container_name=os.getenv(\"BLOB_CONTAINER\") # Name of Azure blob container\n",
    "# account_key=os.getenv(\"BLOB_ACCOUNT_KEY\") # Storage account key\n",
    "\n",
    "# try:\n",
    "#     datastore = Datastore.get(workspace, blob_datastore_name)\n",
    "#     print(\"Found Blob Datastore with name: %s\" % blob_datastore_name)\n",
    "# except HttpOperationError:\n",
    "#     datastore = Datastore.register_azure_blob_container(\n",
    "#        workspace=workspace,\n",
    "#        datastore_name=blob_datastore_name,\n",
    "#        account_name=account_name, # Storage account name\n",
    "#        container_name=container_name, # Name of Azure blob container\n",
    "#        account_key=account_key) # Storage account key\n",
    "#     print(\"Registered blob datastore with name: %s\" % blob_datastore_name)\n",
    "\n",
    "# blob_data_ref = DataReference(\n",
    "#    datastore=blob_datastore,\n",
    "#    data_reference_name=\"blob_test_data\",\n",
    "#    path_on_datastore=\"testdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "interim-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading dataset/mat.csv\n",
      "Uploaded dataset/mat.csv, 1 files out of an estimated total of 2\n",
      "Uploading dataset/por.csv\n",
      "Uploaded dataset/por.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    }
   ],
   "source": [
    "# decide if we want to upload data to cloud\n",
    "if send_dataset_to_cloud:\n",
    "    datastore.upload(\n",
    "        src_dir = local_dataset_source,\n",
    "        target_path = upstream_dataset_path,\n",
    "        overwrite = True,\n",
    "        show_progress = True)\n",
    "\n",
    "# specify dataset path and datastore which stores it\n",
    "datastore_paths = [\n",
    "    (datastore, upstream_dataset_path + 'mat.csv')\n",
    "#     (datastore, upstream_dataset_path + 'por.csv')\n",
    "]\n",
    "\n",
    "# read data from cloud blob as tabular data read from csv files\n",
    "school_dataset = Dataset.Tabular.from_delimited_files(\n",
    "    path=datastore_paths, separator=',',\n",
    "    header=PromoteHeadersBehavior.ALL_FILES_HAVE_SAME_HEADERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-pierce",
   "metadata": {},
   "source": [
    "#### Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "alpha-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_dataset = school_dataset.drop_columns(['Mjob', 'Fjob', 'reason', 'nursery'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-shame",
   "metadata": {},
   "source": [
    "# Split dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "adequate-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = school_dataset.random_split(0.9, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-pizza",
   "metadata": {},
   "source": [
    "### Check for remote AML compute instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "satisfied-think",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "ComputeTarget.list(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-spyware",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
